{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:25:22.329814Z",
     "start_time": "2020-09-07T12:25:22.323053Z"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from fforma import FFORMA\n",
    "import pickle\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "#from tsfeatures import tsfeatures\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:25:22.634416Z",
     "start_time": "2020-09-07T12:25:22.616447Z"
    }
   },
   "outputs": [],
   "source": [
    "#run fforma scripts.\n",
    "%run './Extra_packages/fforma/fforma.py'\n",
    "\n",
    "#run tsfeatures scripts.\n",
    "%run './Extra_packages/tsfeatures/tsfeatures.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:25:23.154321Z",
     "start_time": "2020-09-07T12:25:23.149259Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are a few booleans and variables included determining which parts are run:\n",
    "\"\"\"\n",
    "\n",
    "#Boolean that determines whether time series should be reforecasted\n",
    "reload_forec = False \n",
    "reload_feats = False\n",
    "reload_CI = False\n",
    "reload_meta_learn = False\n",
    "\n",
    "#Variable that determines how long the forecasting horizon is\n",
    "horizon=12 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:25:48.421486Z",
     "start_time": "2020-09-07T12:25:24.932108Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change file to correct folder.\n",
    "original_train = pd.read_csv('./Datafiles/Monthly-train.csv')\n",
    "original_test = pd.read_csv('./Datafiles/Monthly-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:25:49.247591Z",
     "start_time": "2020-09-07T12:25:48.423773Z"
    }
   },
   "outputs": [],
   "source": [
    "original_train_T = original_train.set_index('V1')\n",
    "original_test_T = original_test.set_index('V1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:25:49.554082Z",
     "start_time": "2020-09-07T12:25:49.250119Z"
    }
   },
   "outputs": [],
   "source": [
    "#Helper file that has all forecasting models\n",
    "%run models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:07.768825Z",
     "start_time": "2020-09-07T12:26:07.748590Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell produces and saves all time series forecasts used to train and \n",
    "test the FFORMA model. Running this cell for 8000 time series takes around 48 hours\n",
    "to complete. Note, there is a boolean called CI, which determines in the trainBasicModels function whether it returns point forecasts\n",
    "or prediction intervals. Do note, that not all models in the model pool can produce prediction intervals.\n",
    "\"\"\"\n",
    "\n",
    "#Models that are used in the model pool\n",
    "basic_models = {'Naive': Naive(), 'Naive2':Naive2(), 'SNaive': SeasonalNaive(), 'RWdrift': RandomWalkDrift(), 'ETS':ETS(),\n",
    "               'AutoArima': AutoArima(), 'TBATS':TBATSFF(), 'DTrendS':DTRENDS(), 'RWDriftS':RWDriftS(), 'LLevelS': LLevelS(), 'LLDTrends':LLDTRENDS()}\n",
    "\n",
    "\n",
    "if reload_forec:\n",
    "\n",
    "    #Get forecasts for the first 8000 time series in the TRAINING set.\n",
    "    for x in range(80):\n",
    "\n",
    "        #Create list that you want to forecast\n",
    "        original_train_subs = original_train.iloc[100*x : 100*x + 100]\n",
    "        #original_train_subs = original_train.iloc[x : x +1]\n",
    "        original_train_subs = original_train_subs.set_index('V1')\n",
    "        original_train_subs = original_train_subs.T\n",
    "        unique_id_lst = original_train_subs.columns.tolist()\n",
    "\n",
    "        #Create time series and let it train :-12 elements.\n",
    "        ts_val_train = []\n",
    "        for i in original_train_subs.columns:\n",
    "            ts_val_train.append(original_train_subs[i].dropna().tolist()[:-horizon])\n",
    "\n",
    "        #Create results df\n",
    "        new_index = pd.MultiIndex.from_tuples(zip(np.repeat(unique_id_lst, horizon), list(range(1, horizon+1))*100), names = ['unique_id', 'ds'])\n",
    "\n",
    "        preds_df_new = pd.DataFrame(index = new_index) \n",
    "\n",
    "        #Create predictions\n",
    "        ts_val_train_preds = trainBasicModels().train(basic_models, ts_val_train, frcy).predict(horizon, CI = False) \n",
    "\n",
    "        #Put predictions in dataframe\n",
    "        k=0 \n",
    "        for i in list(basic_models.keys()):\n",
    "            pred_tot = []\n",
    "            for j in ts_val_train_preds:\n",
    "                pred_tot += list(j[k])\n",
    "            preds_df_new[i]  = pred_tot\n",
    "            k += 1\n",
    "\n",
    "        preds_df_new.to_pickle('./Results/Results_curr/Preds_set_{}_{}.pkl'.format(x, horizon))\n",
    "\n",
    "\n",
    "    #Get forecasts for the first 8000 time series in the TESTING set.\n",
    "    for x in range(80):\n",
    "\n",
    "        #Create list that you want to forecast\n",
    "        original_train_subs = original_train.iloc[100*x : 100*x + 100]\n",
    "        original_train_subs = original_train_subs.set_index('V1')\n",
    "        original_train_subs = original_train_subs.T\n",
    "        unique_id_lst = original_train_subs.columns.tolist()\n",
    "\n",
    "        #Create time series and let it train all elements.\n",
    "        ts_val_train = []\n",
    "        for i in original_train_subs.columns:\n",
    "            if horizon == 12:\n",
    "                ts_val_train.append(original_train_subs[i].dropna().tolist())\n",
    "            elif horizon == 36:\n",
    "                ts_val_train.append(original_train_subs[i].dropna().tolist()[:-horizon+12])\n",
    "\n",
    "        #Create results df\n",
    "        new_index = pd.MultiIndex.from_tuples(zip(np.repeat(unique_id_lst, horizon), list(range(1, horizon+1))*100), names = ['unique_id', 'ds'])\n",
    "\n",
    "        preds_df_new = pd.DataFrame(index = new_index) \n",
    "\n",
    "        #Create predictions\n",
    "        ts_val_train_preds = trainBasicModels().train(basic_models, ts_val_train, frcy).predict(horizon, CI = False) #takes 1min30\n",
    "\n",
    "        #Put predictions in dataframe\n",
    "        k=0 \n",
    "        for i in list(basic_models.keys()):\n",
    "            pred_tot = []\n",
    "            for j in ts_val_train_preds:\n",
    "                pred_tot += list(j[k])\n",
    "            preds_df_new[i]  = pred_tot\n",
    "            k += 1\n",
    "\n",
    "        preds_df_new.to_pickle('./Results/Results_curr/Preds_set_{}_full_{}.pkl'.format(x, horizon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Forecasts and do initial manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:10.300927Z",
     "start_time": "2020-09-07T12:26:10.294062Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This cell loads all forecasts and combines them into one file\"\"\"\n",
    "if reload_forec:\n",
    "    new_preds = pd.DataFrame()\n",
    "    for i in range(80):\n",
    "        new_preds = new_preds.append(pd.read_pickle('./Results/Results_curr/Preds_set_{}_{}.pkl'.format(i, horizon)))\n",
    "    new_preds.to_pickle('./Results/Preds_df_train_{}.pkl'.format(horizon))\n",
    "\n",
    "    #Work on adding new pkl files\n",
    "    new_preds = pd.DataFrame()\n",
    "    for i in range(80):\n",
    "        new_preds = new_preds.append(pd.read_pickle('./Results/Results_curr/Preds_set_{}_full_{}.pkl'.format(i, horizon)))\n",
    "    new_preds.to_pickle('./Results/Preds_df_test_{}.pkl'.format(horizon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:13.591321Z",
     "start_time": "2020-09-07T12:26:10.823147Z"
    }
   },
   "outputs": [],
   "source": [
    "CI_df_train_12 = pd.read_pickle('./Results/CI_df_train_12.pkl')\n",
    "CI_df_test_12 = pd.read_pickle('./Results/CI_df_test_12.pkl')\n",
    "preds_df_tot_train_12 = pd.read_pickle('./Results/Preds_df_train_12.pkl')\n",
    "preds_df_tot_test_12 = pd.read_pickle('./Results/Preds_df_test_12.pkl')\n",
    "preds_df_tot_train_36 = pd.read_pickle('./Results/Preds_df_train_36.pkl')\n",
    "preds_df_tot_test_36 = pd.read_pickle('./Results/Preds_df_test_36.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:13.810781Z",
     "start_time": "2020-09-07T12:26:13.600643Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change indices\n",
    "CI_df_train_12.index = pd.MultiIndex.from_tuples(zip(np.repeat(range(1, 8001), 12), list(range(1, 13))*8000), names=['unique_id', 'ds']) \n",
    "CI_df_test_12.index = pd.MultiIndex.from_tuples(zip(np.repeat(range(1, 8001), 12), list(range(1, 13))*8000), names=['unique_id', 'ds']) \n",
    "\n",
    "#Keep only the first 8000 time series\n",
    "preds_df_tot_train_CI_12 = preds_df_tot_train_12.loc[preds_df_tot_train_12.index.get_level_values(0).isin(range(8001))]\n",
    "preds_df_tot_test_CI_12 = preds_df_tot_test_12.loc[preds_df_tot_test_12.index.get_level_values(0).isin(range(8001))]\n",
    "                                                  \n",
    "                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:13.897177Z",
     "start_time": "2020-09-07T12:26:13.816774Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the max index\n",
    "max_nr_12 = list(set(list(preds_df_tot_train_12.index.get_level_values(0))))\n",
    "max_nr_12 = np.max(max_nr_12)\n",
    "\n",
    "max_nr_36 = list(set(list(preds_df_tot_train_36.index.get_level_values(0))))\n",
    "max_nr_36 = np.max(max_nr_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:13.972243Z",
     "start_time": "2020-09-07T12:26:13.954188Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the original time series, and drop the abundant time series in the datafile\n",
    "original_unique_id_12 = ['M' + str(x) for x in range(1, max_nr_12+1)]\n",
    "original_train_T_12 = original_train_T.iloc[:len(original_unique_id_12)]\n",
    "original_train_T_12 = original_train_T_12.T\n",
    "\n",
    "original_test_T_12 = original_test_T.iloc[:len(original_unique_id_12)]\n",
    "original_test_T_12 = original_test_T_12.T\n",
    "\n",
    "original_unique_id_36 = ['M' + str(x) for x in range(1, max_nr_36+1)]\n",
    "original_train_T_36 = original_train_T.iloc[:len(original_unique_id_36)]\n",
    "original_train_T_36 = original_train_T_36.T\n",
    "\n",
    "original_test_T_36 = original_test_T.iloc[:len(original_unique_id_36)]\n",
    "original_test_T_36 = original_test_T_36.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:14.469321Z",
     "start_time": "2020-09-07T12:26:14.448921Z"
    }
   },
   "outputs": [],
   "source": [
    "if reload_feats:\n",
    "    \n",
    "    #horizon 12, train\n",
    "    ts_val_train = []\n",
    "\n",
    "\n",
    "    for i in original_unique_id_12[:8000]:\n",
    "        #use last three years of testing set\n",
    "        ts_val_train.append(original_train_T_12[i].dropna().tolist()[-48:-12])\n",
    "\n",
    "    train_feats_new = pd.DataFrame()\n",
    "\n",
    "    testje_fin = pd.DataFrame(pd.DataFrame(ts_val_train).stack())\n",
    "    testje_fin = testje_fin.rename_axis(index = ['unique_id', 'ds'])\n",
    "    testje_fin = testje_fin.rename(columns = {0:'y'})\n",
    "\n",
    "    constant_indices = pd.DataFrame(testje_fin.groupby('unique_id')['y'].std())\n",
    "    constant_indices = constant_indices.loc[constant_indices.y == 0]\n",
    "    constant_indices = list(constant_indices.index)\n",
    "\n",
    "    testje_fin = testje_fin.loc[~testje_fin.index.get_level_values(0).isin(constant_indices)]\n",
    "\n",
    "    testje_new = tsfeatures(testje_fin, 12)\n",
    "    testje_new.to_pickle('./Results/Feats_train_12_3yr.pkl')\n",
    "    \n",
    "\n",
    "    #horizon 12, test\n",
    "    ts_val_train = []\n",
    "\n",
    "\n",
    "    for i in original_unique_id_12[:8000]:\n",
    "        #use last three years of testing set\n",
    "        ts_val_train.append(original_train_T_12[i].dropna().tolist()[-36:])\n",
    "\n",
    "    train_feats_new = pd.DataFrame()\n",
    "\n",
    "    testje_fin = pd.DataFrame(pd.DataFrame(ts_val_train).stack())\n",
    "    testje_fin = testje_fin.rename_axis(index = ['unique_id', 'ds'])\n",
    "    testje_fin = testje_fin.rename(columns = {0:'y'})\n",
    "\n",
    "    constant_indices = pd.DataFrame(testje_fin.groupby('unique_id')['y'].std())\n",
    "    constant_indices = constant_indices.loc[constant_indices.y == 0]\n",
    "    constant_indices = list(constant_indices.index)\n",
    "\n",
    "    testje_fin = testje_fin.loc[~testje_fin.index.get_level_values(0).isin(constant_indices)]\n",
    "\n",
    "    testje_new = tsfeatures(testje_fin, 12)\n",
    "    testje_new.to_pickle('./Results/Feats_test_12_3yr.pkl')    \n",
    "\n",
    "    #horizon 36, train    \n",
    "    ts_val_train = []    \n",
    "    \n",
    "    for i in original_unique_id_36[:8000]:\n",
    "        ts_val_train.append(original_train_T_36[i].dropna().tolist()[-72:-36])\n",
    "\n",
    "    train_feats_new = pd.DataFrame()\n",
    "\n",
    "    testje_fin = pd.DataFrame(pd.DataFrame(ts_val_train).stack())\n",
    "    testje_fin = testje_fin.rename_axis(index = ['unique_id', 'ds'])\n",
    "    testje_fin = testje_fin.rename(columns = {0:'y'})\n",
    "\n",
    "    constant_indices = pd.DataFrame(testje_fin.groupby('unique_id')['y'].std())\n",
    "    constant_indices = constant_indices.loc[constant_indices.y == 0]\n",
    "    constant_indices = list(constant_indices.index)\n",
    "\n",
    "    testje_fin = testje_fin.loc[~testje_fin.index.get_level_values(0).isin(constant_indices)]\n",
    "\n",
    "    testje_new = tsfeatures(testje_fin, 12)\n",
    "    testje_new.to_pickle('./Results/Feats_train_36_3yr.pkl')\n",
    " \n",
    "    #horizon 36, test    \n",
    "    ts_val_train = []    \n",
    "    \n",
    "    for i in original_unique_id_36[:8000]:\n",
    "        ts_val_train.append(original_train_T_36[i].dropna().tolist()[-72+12:-36+12])\n",
    "\n",
    "    train_feats_new = pd.DataFrame()\n",
    "\n",
    "    testje_fin = pd.DataFrame(pd.DataFrame(ts_val_train).stack())\n",
    "    testje_fin = testje_fin.rename_axis(index = ['unique_id', 'ds'])\n",
    "    testje_fin = testje_fin.rename(columns = {0:'y'})\n",
    "\n",
    "    constant_indices = pd.DataFrame(testje_fin.groupby('unique_id')['y'].std())\n",
    "    constant_indices = constant_indices.loc[constant_indices.y == 0]\n",
    "    constant_indices = list(constant_indices.index)\n",
    "\n",
    "    testje_fin = testje_fin.loc[~testje_fin.index.get_level_values(0).isin(constant_indices)]\n",
    "\n",
    "    testje_new = tsfeatures(testje_fin, 12)\n",
    "    testje_new.to_pickle('./Results/Feats_test_36_3yr.pkl')    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:15.919797Z",
     "start_time": "2020-09-07T12:26:15.903627Z"
    }
   },
   "outputs": [],
   "source": [
    "#Order of feats that has been used in the training of the meta-learning models per horizon\n",
    "\n",
    "columns_12 = ['hw_beta', 'unitroot_pp', 'alpha', 'arch_lm', 'flat_spots',\n",
    "       'diff1_acf10', 'curvature', 'beta', 'garch_acf', 'seas_pacf',\n",
    "       'seasonal_strength', 'hw_gamma', 'seas_acf1', 'x_pacf5', 'spike',\n",
    "       'seasonal_period', 'peak', 'hurst', 'unitroot_kpss', 'trend', 'x_acf1',\n",
    "       'diff2_acf1', 'x_acf10', 'entropy', 'diff2_acf10', 'e_acf10',\n",
    "       'stability', 'garch_r2', 'trough', 'diff2x_pacf5', 'lumpiness',\n",
    "       'diff1x_pacf5', 'arch_r2', 'nonlinearity', 'nperiods', 'diff1_acf1',\n",
    "       'hw_alpha', 'arch_acf', 'linearity', 'e_acf1', 'series_length',\n",
    "       'crossing_points']\n",
    "\n",
    "columns_36 = ['alpha', 'arch_acf', 'arch_lm', 'arch_r2', 'beta', 'crossing_points',\n",
    "       'curvature', 'diff1_acf1', 'diff1_acf10', 'diff1x_pacf5', 'diff2_acf1',\n",
    "       'diff2_acf10', 'diff2x_pacf5', 'e_acf1', 'e_acf10', 'entropy',\n",
    "       'flat_spots', 'garch_acf', 'garch_r2', 'hurst', 'hw_alpha', 'hw_beta',\n",
    "       'hw_gamma', 'linearity', 'lumpiness', 'nonlinearity', 'nperiods',\n",
    "       'peak', 'seas_acf1', 'seas_pacf', 'seasonal_period',\n",
    "       'seasonal_strength', 'series_length', 'spike', 'stability', 'trend',\n",
    "       'trough', 'unitroot_kpss', 'unitroot_pp', 'x_acf1', 'x_acf10',\n",
    "       'x_pacf5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:16.351387Z",
     "start_time": "2020-09-07T12:26:16.301655Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the features used for training and testing.\n",
    "\n",
    "XXXX: Check whether this is the correct set of features (see files)\n",
    "\"\"\"\n",
    "\n",
    "train_feats_tot_12 = pd.read_pickle('./Results/Feats_train_12_3yr.pkl')\n",
    "test_feats_tot_12 = pd.read_pickle('./Results/Feats_test_12_3yr.pkl')\n",
    "\n",
    "train_feats_tot_36 = pd.read_pickle('./Results/Feats_train_36_3yr.pkl')\n",
    "test_feats_tot_36 = pd.read_pickle('./Results/Feats_test_36_3yr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:17.682227Z",
     "start_time": "2020-09-07T12:26:17.651798Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feats_tot_12 = train_feats_tot_12[columns_12]\n",
    "train_feats_tot_36 = train_feats_tot_36[columns_36]\n",
    "\n",
    "test_feats_tot_12 = test_feats_tot_12[columns_12]\n",
    "test_feats_tot_36 = test_feats_tot_36[columns_36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:26:17.956006Z",
     "start_time": "2020-09-07T12:26:17.921758Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change index to match the index of the predictions\n",
    "train_feats_tot_12.index = [int(x+1) for x in train_feats_tot_12.index]\n",
    "test_feats_tot_12.index = [int(x+1) for x in test_feats_tot_12.index]    \n",
    "\n",
    "train_feats_tot_36.index = [int(x+1) for x in train_feats_tot_36.index]\n",
    "test_feats_tot_36.index = [int(x+1) for x in test_feats_tot_36.index]    \n",
    "\n",
    "ids = list(range(1, 8001))\n",
    "ids = ['M{}'.format(x) for x in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:33.408241Z",
     "start_time": "2020-09-07T12:26:18.254674Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check which indices are both in the feats and the predictions\n",
    "indices_used_12 = [x for x in list(train_feats_tot_12.index) if x in list(test_feats_tot_12.index)]\n",
    "indices_used_12 = [x for x in indices_used_12 if x in preds_df_tot_test_12.index.get_level_values(0)]\n",
    "\n",
    "indices_used_36 = [x for x in list(train_feats_tot_36.index) if x in list(test_feats_tot_36.index)]\n",
    "indices_used_36 = [x for x in indices_used_36 if x in preds_df_tot_test_36.index.get_level_values(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:33.578068Z",
     "start_time": "2020-09-07T12:27:33.428979Z"
    }
   },
   "outputs": [],
   "source": [
    "#Remove indices that are not both in the feats and the predictions\n",
    "preds_df_tot_test_12 = preds_df_tot_test_12.loc[preds_df_tot_test_12.index.get_level_values(0).isin(indices_used_12)]\n",
    "preds_df_tot_train_12 = preds_df_tot_train_12.loc[preds_df_tot_train_12.index.get_level_values(0).isin(indices_used_12)]\n",
    "\n",
    "preds_df_tot_test_36 = preds_df_tot_test_36.loc[preds_df_tot_test_36.index.get_level_values(0).isin(indices_used_36)]\n",
    "preds_df_tot_train_36 = preds_df_tot_train_36.loc[preds_df_tot_train_36.index.get_level_values(0).isin(indices_used_36)]\n",
    "\n",
    "train_feats_tot_12 = train_feats_tot_12.loc[train_feats_tot_12.index.isin(indices_used_12)]\n",
    "test_feats_tot_12 = test_feats_tot_12.loc[test_feats_tot_12.index.isin(indices_used_12)]\n",
    "\n",
    "train_feats_tot_36 = train_feats_tot_36.loc[train_feats_tot_36.index.isin(indices_used_36)]\n",
    "test_feats_tot_36 = test_feats_tot_36.loc[test_feats_tot_36.index.isin(indices_used_36)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:33.587372Z",
     "start_time": "2020-09-07T12:27:33.582056Z"
    }
   },
   "outputs": [],
   "source": [
    "#Give the correct formatting for the FFORMA model\n",
    "test_feats_tot_12.index.name = 'unique_id'\n",
    "train_feats_tot_12.index.name = 'unique_id'\n",
    "\n",
    "test_feats_tot_36.index.name = 'unique_id'\n",
    "train_feats_tot_36.index.name = 'unique_id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:33.867939Z",
     "start_time": "2020-09-07T12:27:33.590475Z"
    }
   },
   "outputs": [],
   "source": [
    "#Rematch indices\n",
    "\n",
    "index_integers_12 = list(train_feats_tot_12.index)\n",
    "index_integers_36 = list(train_feats_tot_36.index)\n",
    "\n",
    "\n",
    "index_integers_multi_12 = np.repeat(index_integers_12, 12)\n",
    "index_integers_multi_36 = np.repeat(index_integers_36, 36)\n",
    "\n",
    "multi_index_12 = pd.MultiIndex.from_tuples(zip(index_integers_multi_12, list(preds_df_tot_train_12.index.get_level_values(1))), names = ['unique_id', 'ds'])\n",
    "multi_index_36 = pd.MultiIndex.from_tuples(zip(index_integers_multi_36, list(preds_df_tot_train_36.index.get_level_values(1))), names = ['unique_id', 'ds'])\n",
    "\n",
    "preds_df_tot_test_12.index = multi_index_12\n",
    "preds_df_tot_train_12.index = multi_index_12\n",
    "\n",
    "preds_df_tot_test_36.index = multi_index_36\n",
    "preds_df_tot_train_36.index = multi_index_36\n",
    "\n",
    "train_feats_tot_12.index = index_integers_12\n",
    "train_feats_tot_12.index.name = 'unique_id'\n",
    "\n",
    "test_feats_tot_36.index = index_integers_36\n",
    "test_feats_tot_36.index.name = 'unique_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:34.232671Z",
     "start_time": "2020-09-07T12:27:33.869999Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create errors dataframe\n",
    "index_feats_12 = list(train_feats_tot_12.index)\n",
    "\n",
    "index_feats_36 = list(train_feats_tot_36.index)\n",
    "\n",
    "errors_df_tot_train_12 = pd.DataFrame(index = preds_df_tot_train_12.index, columns = preds_df_tot_train_12.columns)\n",
    "\n",
    "errors_df_tot_train_36 = pd.DataFrame(index = preds_df_tot_train_36.index, columns = preds_df_tot_train_36.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:44.004585Z",
     "start_time": "2020-09-07T12:27:34.235818Z"
    }
   },
   "outputs": [],
   "source": [
    "#Errors for training set\n",
    "\n",
    "ts_val_actual = []\n",
    "for i in index_feats_12:\n",
    "    ts_val_actual.append(original_train_T_12['M{}'.format(i)].dropna().tolist()[-12:])\n",
    "\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_tot_train_12.columns:\n",
    "    errors_df_tot_train_12[i] = ts_val_actual_flat\n",
    "\n",
    "#percentage errors\n",
    "errors_df_tot_train_12 = ((errors_df_tot_train_12 - preds_df_tot_train_12)/errors_df_tot_train_12)*100\n",
    "\n",
    "    \n",
    "ts_val_actual = []\n",
    "for i in index_feats_36:\n",
    "    ts_val_actual.append(original_train_T_36['M{}'.format(i)].dropna().tolist()[-36:])\n",
    "\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_tot_train_36.columns:\n",
    "    errors_df_tot_train_36[i] = ts_val_actual_flat\n",
    "\n",
    "#percentage errors\n",
    "errors_df_tot_train_36 = ((errors_df_tot_train_36 - preds_df_tot_train_36)/errors_df_tot_train_36)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:44.076140Z",
     "start_time": "2020-09-07T12:27:44.006554Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create dictionary that maps original index to new index\n",
    "original_nrs_12 = list(set(list(errors_df_tot_train_12.index.get_level_values(0))))\n",
    "original_nrs_dict_12 = dict(zip(original_nrs_12, list(range(len(original_nrs_12)))))\n",
    "original_nrs_dict_rev_12 = {value:key for key, value in original_nrs_dict_12.items()}\n",
    "\n",
    "original_nrs_36 = list(set(list(errors_df_tot_train_36.index.get_level_values(0))))\n",
    "original_nrs_dict_36 = dict(zip(original_nrs_36, list(range(len(original_nrs_36)))))\n",
    "original_nrs_dict_rev_36 = {value:key for key, value in original_nrs_dict_36.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:44.357887Z",
     "start_time": "2020-09-07T12:27:44.080115Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change index of errors df\n",
    "errors_df_tot_train_12.index = pd.MultiIndex.from_tuples(zip(np.repeat(list(range(len(original_nrs_12))), 12), list(errors_df_tot_train_12.index.get_level_values(1))), names = ['unique_id', 'ds'])\n",
    "\n",
    "errors_df_tot_train_36.index = pd.MultiIndex.from_tuples(zip(np.repeat(list(range(len(original_nrs_36))), 36), list(errors_df_tot_train_36.index.get_level_values(1))), names = ['unique_id', 'ds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:44.368495Z",
     "start_time": "2020-09-07T12:27:44.359999Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feats_tot_12.index = list(range(len(original_nrs_12)))\n",
    "train_feats_tot_12.index.name = 'unique_id'\n",
    "\n",
    "train_feats_tot_36.index = list(range(len(original_nrs_36)))\n",
    "train_feats_tot_36.index.name = 'unique_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:44.378213Z",
     "start_time": "2020-09-07T12:27:44.370513Z"
    }
   },
   "outputs": [],
   "source": [
    "test_feats_tot_12.index = list(range(len(original_nrs_12)))\n",
    "test_feats_tot_12.index.name = 'unique_id'\n",
    "\n",
    "test_feats_tot_36.index = list(range(len(original_nrs_36)))\n",
    "test_feats_tot_36.index.name = 'unique_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:27:44.666792Z",
     "start_time": "2020-09-07T12:27:44.380519Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_df_tot_test_12.index = pd.MultiIndex.from_tuples(zip(np.repeat(list(range(len(original_nrs_12))), 12), list(errors_df_tot_train_12.index.get_level_values(1))), names = ['unique_id', 'ds'])\n",
    "\n",
    "preds_df_tot_test_36.index = pd.MultiIndex.from_tuples(zip(np.repeat(list(range(len(original_nrs_36))), 36), list(errors_df_tot_train_36.index.get_level_values(1))), names = ['unique_id', 'ds'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find bounds for CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:05.234834Z",
     "start_time": "2020-09-07T12:28:05.231722Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Divide the dataset into two parts, A and B. Train the fforma on A and predict B, and vice versa.\n",
    "You now have fforma predictions. \n",
    "Then train a meta-learning model that predicts the optimal ensemble\n",
    "based on the MSIS measure\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:05.921986Z",
     "start_time": "2020-09-07T12:28:05.803537Z"
    }
   },
   "outputs": [],
   "source": [
    "#Drop the LLevel\n",
    "CI_df_train_12 = CI_df_train_12.drop(columns = 'LLevel')\n",
    "CI_df_test_12 = CI_df_test_12.drop(columns = 'LLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:06.375899Z",
     "start_time": "2020-09-07T12:28:06.362512Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a new preds dataframe with the correct column names\n",
    "preds_df_tot_train_CI_12 = preds_df_tot_train_CI_12[CI_df_train_12.columns]\n",
    "preds_df_tot_test_CI_12 = preds_df_tot_test_CI_12[CI_df_train_12.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:07.901473Z",
     "start_time": "2020-09-07T12:28:06.993891Z"
    }
   },
   "outputs": [],
   "source": [
    "#Assuming that the bounds are symmetric, we keep only the lower bound\n",
    "for i in CI_df_train_12.columns:\n",
    "    CI_df_train_12[i] = CI_df_train_12[i].map(lambda x: x[-1])\n",
    "\n",
    "for i in CI_df_test_12.columns:\n",
    "    CI_df_test_12[i] = CI_df_test_12[i].map(lambda x: x[-1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:07.987444Z",
     "start_time": "2020-09-07T12:28:07.903715Z"
    }
   },
   "outputs": [],
   "source": [
    "#Keep only those indices that are in the prediction interval and in the prediction\n",
    "CI_df_train_12 = CI_df_train_12.loc[CI_df_train_12.index.get_level_values(0).isin(preds_df_tot_train_CI_12.index.get_level_values(0))]\n",
    "CI_df_test_12 = CI_df_test_12.loc[CI_df_test_12.index.get_level_values(0).isin(preds_df_tot_test_CI_12.index.get_level_values(0))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:08.180013Z",
     "start_time": "2020-09-07T12:28:08.157228Z"
    }
   },
   "outputs": [],
   "source": [
    "#Take the differences to create the prediction interval 'radius'\n",
    "differences_CI_train_12 = (CI_df_train_12 - preds_df_tot_train_CI_12)\n",
    "differences_CI_test_12 = (CI_df_test_12 - preds_df_tot_test_CI_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:08.619104Z",
     "start_time": "2020-09-07T12:28:08.597666Z"
    }
   },
   "outputs": [],
   "source": [
    "all_ids_12 = list(set(errors_df_tot_train_12.index.get_level_values(0).unique()))\n",
    "\n",
    "#Create set A and set B\n",
    "y_1 = [x for x in all_ids_12 if x < 2000 or x > 6000]\n",
    "y_2 = [x for x in all_ids_12 if x >= 2000 and x <= 6000]\n",
    "\n",
    "train_feats_tot1_12 = train_feats_tot_12.loc[train_feats_tot_12.index.isin(y_1)]\n",
    "train_feats_tot2_12 = train_feats_tot_12.loc[train_feats_tot_12.index.isin(y_2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:09.039341Z",
     "start_time": "2020-09-07T12:28:09.032357Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create dictionaries to switch between old and new index\n",
    "dict_index_part1 = dict(zip(y_1, range(len(y_1))))\n",
    "dict_index_part2 = dict(zip(y_2, range(len(y_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:09.735241Z",
     "start_time": "2020-09-07T12:28:09.632225Z"
    }
   },
   "outputs": [],
   "source": [
    "#Keep only correct errors\n",
    "errors_df_tot_train1_12 = errors_df_tot_train_12.loc[errors_df_tot_train_12.index.get_level_values(0).isin(y_1)]\n",
    "errors_df_tot_train2_12 = errors_df_tot_train_12.loc[errors_df_tot_train_12.index.get_level_values(0).isin(y_2)]\n",
    "\n",
    "#Change index\n",
    "errors_df_tot_train1_12.index = pd.MultiIndex.from_tuples(zip(np.repeat(range(len(y_1)), 12), list(range(1, 13))*len(y_1)), names=['unique_id', 'ds'])\n",
    "errors_df_tot_train2_12.index = pd.MultiIndex.from_tuples(zip(np.repeat(range(len(y_2)), 12), list(range(1, 13))*len(y_2)), names=['unique_id', 'ds'])\n",
    "\n",
    "#Get correct feats train\n",
    "train_feats_tot1_12 = train_feats_tot_12.loc[train_feats_tot_12.index.isin(y_1)]\n",
    "train_feats_tot2_12 = train_feats_tot_12.loc[train_feats_tot_12.index.isin(y_2)]\n",
    "\n",
    "train_feats_tot1_12.index = range(len(y_1))\n",
    "train_feats_tot2_12.index = range(len(y_2))\n",
    "train_feats_tot1_12.index.name = 'unique_id'\n",
    "train_feats_tot2_12.index.name = 'unique_id'\n",
    "\n",
    "#Get correct feats test\n",
    "test_feats_tot1_12 = test_feats_tot_12.loc[test_feats_tot_12.index.isin(y_1)]\n",
    "test_feats_tot2_12 = test_feats_tot_12.loc[test_feats_tot_12.index.isin(y_2)]\n",
    "\n",
    "test_feats_tot1_12.index = range(len(y_1))\n",
    "test_feats_tot2_12.index = range(len(y_2))\n",
    "test_feats_tot1_12.index.name = 'unique_id'\n",
    "test_feats_tot2_12.index.name = 'unique_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:10.225309Z",
     "start_time": "2020-09-07T12:28:10.216029Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feats_tot1_12 = train_feats_tot1_12[columns_12]\n",
    "train_feats_tot2_12 = train_feats_tot2_12[columns_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:10.964525Z",
     "start_time": "2020-09-07T12:28:10.955911Z"
    }
   },
   "outputs": [],
   "source": [
    "if reload_CI:\n",
    "    #Train the two models that determine the FFORMA forecasts\n",
    "    optimal_params = {'n_estimators': 150,\n",
    "                      'eta': 0.1,\n",
    "                      'max_depth': 18,\n",
    "                      'subsample': 0.8,\n",
    "                      'colsample_bytree': 0.6}\n",
    "\n",
    "    model1 = FFORMA(params=optimal_params, early_stopping_rounds = 10, verbose_eval=1, greedy_search = False)\n",
    "    model2 = FFORMA(params=optimal_params, early_stopping_rounds = 10, verbose_eval=1, greedy_search = False)\n",
    "\n",
    "    model1.fit(errors = errors_df_tot_train1_12, holdout_feats = train_feats_tot1_12, feats = test_feats_tot1_12)\n",
    "    model2.fit(errors = errors_df_tot_train2_12, holdout_feats = train_feats_tot2_12, feats = test_feats_tot2_12)\n",
    "\n",
    "    #Save the two models\n",
    "    pickle.dump(model1.lgb, open(\"./Predictions/Final/Final/model1_new.pickle.dat\", \"wb\"))\n",
    "    pickle.dump(model2.lgb, open(\"./Predictions/Final/Final/model2_new.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta-learning models based on MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:24.141706Z",
     "start_time": "2020-09-07T12:28:24.134021Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = []\n",
    "\n",
    "if reload_meta_learn:\n",
    "    optimal_params = {'n_estimators': 150,\n",
    "                      'eta': 0.1,\n",
    "                      'max_depth': 18,\n",
    "                      'subsample': 0.8,\n",
    "                      'colsample_bytree': 0.6}\n",
    "\n",
    "    #Model for horizon 12\n",
    "    model_12 = FFORMA(params=optimal_params, early_stopping_rounds = 10, verbose_eval=1, greedy_search = False, original_article = False)\n",
    "    model_12.fit(errors=errors_df_tot_train_12.drop(columns=drop_cols), holdout_feats=train_feats_tot_12, feats=test_feats_tot_12)\n",
    "\n",
    "    #Model for horizon 36\n",
    "    model_36 = FFORMA(params=optimal_params, early_stopping_rounds = 10, verbose_eval=1, greedy_search = False, original_article = False)\n",
    "    model_36.fit(errors=errors_df_tot_train_36.drop(columns=drop_cols), holdout_feats=train_feats_tot_36, feats=test_feats_tot_36)\n",
    "    \n",
    "    #Save models\n",
    "    pickle.dump(model_12.lgb, open(\"./Models/model_12_150.pickle.dat\", \"wb\"))\n",
    "    pickle.dump(model_36.lgb, open(\"./Models/model_36_150.pickle.dat\", \"wb\"))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:24.926066Z",
     "start_time": "2020-09-07T12:28:24.651148Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load all models\n",
    "model_lgb = pickle.load(open('./Models/model.pickle.dat', 'rb'))\n",
    "model_36_lgb = pickle.load(open('./Models/model_36_149.pickle.dat', 'rb'))\n",
    "\n",
    "model1_lgb = pickle.load(open('./Models/model1_new.pickle.dat', 'rb'))\n",
    "model2_lgb = pickle.load(open('./Models/model2_new.pickle.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check FFORMA performance of MAPE in-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:26.674450Z",
     "start_time": "2020-09-07T12:28:26.670790Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "12 mo - 5yr:\n",
    "model_lgb = pickle.load(open('./Predictions/Final/Final/model_5yr_145.pickle.dat', 'rb'))\n",
    "train_feats_tot_12 = pd.read_pickle('./Predictions/Final/Final/feats_train_12_5yr.pkl')\n",
    "test_feats_tot_12 = pd.read_pickle('./Predictions/Final/Final/feats_test_12_5yr.pkl')\n",
    "\n",
    "12 mo - 7yr:\n",
    "model_lgb = pickle.load(open('./Predictions/Final/Final/model_7yr_137.pickle.dat', 'rb'))\n",
    "\n",
    "36 mo - 3yr:\n",
    "model_36_lgb = pickle.load(open('./Predictions/Final/Final/model_36_149.pickle.dat', 'rb'))\n",
    "\n",
    "36 mo - 5yr:\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:28.670108Z",
     "start_time": "2020-09-07T12:28:27.044256Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols=[]\n",
    "\n",
    "#weights trainingset\n",
    "weights_insample_12 = scipy.special.softmax(model_lgb.predict(train_feats_tot_12), axis = 1)\n",
    "weights_insample_36 = scipy.special.softmax(model_36_lgb.predict(train_feats_tot_36), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:29.488776Z",
     "start_time": "2020-09-07T12:28:29.321099Z"
    }
   },
   "outputs": [],
   "source": [
    "#add fforma predictions to the models\n",
    "preds_df_insample_12 = preds_df_tot_train_12.drop(columns=drop_cols).copy()\n",
    "preds_df_insample_12['fforma'] = (np.repeat(weights_insample_12, 12, axis = 0)*preds_df_insample_12).sum(axis = 1)\n",
    "\n",
    "preds_df_insample_36 = preds_df_tot_train_36.copy()\n",
    "preds_df_insample_36['fforma'] = (np.repeat(weights_insample_36, 36, axis = 0)*preds_df_insample_36).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:34.744364Z",
     "start_time": "2020-09-07T12:28:31.006598Z"
    }
   },
   "outputs": [],
   "source": [
    "#Insample fit:\n",
    "errors_df_insample_12 = pd.DataFrame(index = preds_df_insample_12.index, columns = preds_df_insample_12.columns)\n",
    "\n",
    "#Errors for train\n",
    "ts_val_actual = []\n",
    "for i in index_feats_12:\n",
    "    ts_val_actual.append(original_train_T_12['M{}'.format(i)].dropna().tolist()[-12:])\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "for i in errors_df_insample_12.columns:\n",
    "    errors_df_insample_12[i] = ts_val_actual_flat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:38.646753Z",
     "start_time": "2020-09-07T12:28:34.753355Z"
    }
   },
   "outputs": [],
   "source": [
    "#Insample fit:\n",
    "errors_df_insample_36 = pd.DataFrame(index = preds_df_insample_36.index, columns = preds_df_insample_36.columns)\n",
    "\n",
    "#Errors for train\n",
    "ts_val_actual = []\n",
    "for i in index_feats_36:\n",
    "    ts_val_actual.append(original_train_T_36['M{}'.format(i)].dropna().tolist()[-36:])\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "for i in errors_df_insample_36.columns:\n",
    "    errors_df_insample_36[i] = ts_val_actual_flat       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:39.001174Z",
     "start_time": "2020-09-07T12:28:38.648881Z"
    }
   },
   "outputs": [],
   "source": [
    "#Turn into MAPE\n",
    "errors_df_insample_12 = np.abs(((errors_df_insample_12 - preds_df_insample_12)/errors_df_insample_12)*100)\n",
    "errors_df_insample_36 = np.abs(((errors_df_insample_36 - preds_df_insample_36)/errors_df_insample_36)*100)\n",
    "\n",
    "errors_df_insample_12.index.names = ['unique_id', 'ds']\n",
    "errors_df_insample_36.index.names = ['unique_id', 'ds']\n",
    "\n",
    "errors_df_insample_12 = errors_df_insample_12.groupby('unique_id')[errors_df_insample_12.columns].mean()\n",
    "errors_df_insample_36 = errors_df_insample_36.groupby('unique_id')[errors_df_insample_36.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:39.702137Z",
     "start_time": "2020-09-07T12:28:39.619356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive2</th>\n",
       "      <th>SNaive</th>\n",
       "      <th>RWdrift</th>\n",
       "      <th>ETS</th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.78</td>\n",
       "      <td>12.70</td>\n",
       "      <td>13.57</td>\n",
       "      <td>13.82</td>\n",
       "      <td>13.05</td>\n",
       "      <td>18.73</td>\n",
       "      <td>11.46</td>\n",
       "      <td>16.42</td>\n",
       "      <td>12.71</td>\n",
       "      <td>11.49</td>\n",
       "      <td>12.29</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.23</td>\n",
       "      <td>33.42</td>\n",
       "      <td>21.89</td>\n",
       "      <td>35.43</td>\n",
       "      <td>25.75</td>\n",
       "      <td>51.08</td>\n",
       "      <td>23.35</td>\n",
       "      <td>30.50</td>\n",
       "      <td>29.61</td>\n",
       "      <td>24.88</td>\n",
       "      <td>28.43</td>\n",
       "      <td>14.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.92</td>\n",
       "      <td>5.70</td>\n",
       "      <td>7.13</td>\n",
       "      <td>6.89</td>\n",
       "      <td>6.24</td>\n",
       "      <td>7.14</td>\n",
       "      <td>5.43</td>\n",
       "      <td>6.97</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.55</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1853.54</td>\n",
       "      <td>1853.54</td>\n",
       "      <td>555.41</td>\n",
       "      <td>1926.53</td>\n",
       "      <td>1374.58</td>\n",
       "      <td>2231.11</td>\n",
       "      <td>887.02</td>\n",
       "      <td>697.02</td>\n",
       "      <td>1761.91</td>\n",
       "      <td>1480.39</td>\n",
       "      <td>1671.49</td>\n",
       "      <td>556.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Naive   Naive2  SNaive  RWdrift      ETS  AutoArima   TBATS  DTrendS  \\\n",
       "mean    13.78    12.70   13.57    13.82    13.05      18.73   11.46    16.42   \n",
       "std     34.23    33.42   21.89    35.43    25.75      51.08   23.35    30.50   \n",
       "min      0.00     0.11    0.00     0.16     0.17       0.00    0.00     0.13   \n",
       "50%      6.92     5.70    7.13     6.89     6.24       7.14    5.43     6.97   \n",
       "max   1853.54  1853.54  555.41  1926.53  1374.58    2231.11  887.02   697.02   \n",
       "\n",
       "      RWDriftS  LLevelS  LLDTrends  fforma  \n",
       "mean     12.71    11.49      12.29    9.00  \n",
       "std      29.61    24.88      28.43   14.16  \n",
       "min       0.08     0.15       0.08    0.07  \n",
       "50%       5.71     5.55       5.60    4.61  \n",
       "max    1761.91  1480.39    1671.49  556.64  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Horizon 12\n",
    "errors_df_insample_12.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:41.286355Z",
     "start_time": "2020-09-07T12:28:41.212123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive2</th>\n",
       "      <th>SNaive</th>\n",
       "      <th>RWdrift</th>\n",
       "      <th>ETS</th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.87</td>\n",
       "      <td>17.14</td>\n",
       "      <td>20.29</td>\n",
       "      <td>19.08</td>\n",
       "      <td>17.23</td>\n",
       "      <td>49.51</td>\n",
       "      <td>12174.25</td>\n",
       "      <td>27.29</td>\n",
       "      <td>20.40</td>\n",
       "      <td>16.67</td>\n",
       "      <td>19.98</td>\n",
       "      <td>13.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.63</td>\n",
       "      <td>29.59</td>\n",
       "      <td>32.25</td>\n",
       "      <td>33.99</td>\n",
       "      <td>29.01</td>\n",
       "      <td>98.23</td>\n",
       "      <td>1086675.65</td>\n",
       "      <td>61.00</td>\n",
       "      <td>38.08</td>\n",
       "      <td>28.65</td>\n",
       "      <td>38.99</td>\n",
       "      <td>20.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.94</td>\n",
       "      <td>9.10</td>\n",
       "      <td>10.45</td>\n",
       "      <td>9.57</td>\n",
       "      <td>9.42</td>\n",
       "      <td>17.32</td>\n",
       "      <td>9.40</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.68</td>\n",
       "      <td>8.95</td>\n",
       "      <td>9.47</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1150.05</td>\n",
       "      <td>1154.12</td>\n",
       "      <td>1135.19</td>\n",
       "      <td>1264.34</td>\n",
       "      <td>1115.50</td>\n",
       "      <td>2608.88</td>\n",
       "      <td>97177021.59</td>\n",
       "      <td>2342.72</td>\n",
       "      <td>1372.57</td>\n",
       "      <td>1145.15</td>\n",
       "      <td>1530.67</td>\n",
       "      <td>733.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Naive   Naive2   SNaive  RWdrift      ETS  AutoArima        TBATS  \\\n",
       "mean    17.87    17.14    20.29    19.08    17.23      49.51     12174.25   \n",
       "std     29.63    29.59    32.25    33.99    29.01      98.23   1086675.65   \n",
       "min      0.00     0.19     0.17     0.12     0.00       0.14         0.00   \n",
       "50%      9.94     9.10    10.45     9.57     9.42      17.32         9.40   \n",
       "max   1150.05  1154.12  1135.19  1264.34  1115.50    2608.88  97177021.59   \n",
       "\n",
       "      DTrendS  RWDriftS  LLevelS  LLDTrends  fforma  \n",
       "mean    27.29     20.40    16.67      19.98   13.75  \n",
       "std     61.00     38.08    28.65      38.99   20.53  \n",
       "min      0.25      0.28     0.11       0.28    0.26  \n",
       "50%     11.28      9.68     8.95       9.47    7.89  \n",
       "max   2342.72   1372.57  1145.15    1530.67  733.13  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Horizon 36\n",
    "errors_df_insample_36.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check performance FFORMA of MAPE out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:43.260011Z",
     "start_time": "2020-09-07T12:28:43.250234Z"
    }
   },
   "outputs": [],
   "source": [
    "test_feats_tot_12 = test_feats_tot_12[columns_12]\n",
    "test_feats_tot_36 = test_feats_tot_36[columns_36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:45.636398Z",
     "start_time": "2020-09-07T12:28:43.562888Z"
    }
   },
   "outputs": [],
   "source": [
    "#weights testingset\n",
    "\n",
    "weights_outsample_12 = scipy.special.softmax(model_lgb.predict(test_feats_tot_12), axis = 1)\n",
    "\n",
    "weights_outsample_36 = scipy.special.softmax(model_36_lgb.predict(test_feats_tot_36), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:46.267662Z",
     "start_time": "2020-09-07T12:28:46.189469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive2</th>\n",
       "      <th>SNaive</th>\n",
       "      <th>RWdrift</th>\n",
       "      <th>ETS</th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive  Naive2  SNaive  RWdrift   ETS  AutoArima  TBATS  DTrendS  \\\n",
       "mean   0.06    0.09    0.05     0.07  0.10       0.04   0.15     0.04   \n",
       "std    0.06    0.06    0.05     0.07  0.09       0.11   0.10     0.06   \n",
       "min    0.00    0.00    0.00     0.00  0.00       0.00   0.00     0.00   \n",
       "50%    0.04    0.08    0.04     0.05  0.09       0.00   0.13     0.03   \n",
       "max    0.51    0.56    0.66     0.59  0.74       0.99   0.95     0.79   \n",
       "\n",
       "      RWDriftS  LLevelS  LLDTrends  \n",
       "mean      0.11     0.16       0.13  \n",
       "std       0.10     0.08       0.08  \n",
       "min       0.00     0.00       0.00  \n",
       "50%       0.08     0.17       0.11  \n",
       "max       0.74     0.81       0.82  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check ensemble weights for horizon 12\n",
    "pd.DataFrame(data = weights_outsample_12, columns = preds_df_tot_test_12.drop(columns=drop_cols).columns).describe().iloc[[1, 2, 3, 5, 7]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:48.163253Z",
     "start_time": "2020-09-07T12:28:48.082590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive2</th>\n",
       "      <th>SNaive</th>\n",
       "      <th>RWdrift</th>\n",
       "      <th>ETS</th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive  Naive2  SNaive  RWdrift   ETS  AutoArima  TBATS  DTrendS  \\\n",
       "mean   0.10    0.13    0.07     0.09  0.15       0.01   0.12     0.02   \n",
       "std    0.08    0.06    0.06     0.08  0.07       0.04   0.13     0.03   \n",
       "min    0.00    0.00    0.00     0.00  0.00       0.00   0.00     0.00   \n",
       "50%    0.10    0.13    0.06     0.06  0.15       0.00   0.08     0.01   \n",
       "max    0.76    0.72    0.70     0.68  0.70       0.84   0.92     0.30   \n",
       "\n",
       "      RWDriftS  LLevelS  LLDTrends  \n",
       "mean      0.04     0.21       0.06  \n",
       "std       0.04     0.07       0.07  \n",
       "min       0.00     0.00       0.00  \n",
       "50%       0.03     0.22       0.04  \n",
       "max       0.47     0.59       0.82  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check ensemble weights for horizon 36\n",
    "pd.DataFrame(data = weights_outsample_36, columns = preds_df_tot_test_36.drop(columns=drop_cols).columns).describe().iloc[[1, 2, 3, 5, 7]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:50.143051Z",
     "start_time": "2020-09-07T12:28:50.013854Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create FFORMA forecasts\n",
    "preds_df_outsample_12 = preds_df_tot_test_12.drop(columns=drop_cols).copy()\n",
    "preds_df_outsample_12['fforma'] = (np.repeat(weights_outsample_12, 12, axis = 0)*preds_df_outsample_12).sum(axis = 1)\n",
    "\n",
    "preds_df_outsample_36 = preds_df_tot_test_36.copy()\n",
    "preds_df_outsample_36['fforma'] = (np.repeat(weights_outsample_36, 36, axis = 0)*preds_df_outsample_36).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:28:54.153784Z",
     "start_time": "2020-09-07T12:28:50.389373Z"
    }
   },
   "outputs": [],
   "source": [
    "#Out-of-sample fit horizon 12\n",
    "errors_df_outsample_12 = pd.DataFrame(index = preds_df_outsample_12.index, columns = preds_df_outsample_12.columns)\n",
    "\n",
    "#Errors for train\n",
    "ts_val_actual = []\n",
    "for i in index_feats_12:\n",
    "    ts_val_actual.append(original_test_T_12['M{}'.format(i)].dropna().tolist()[:12])\n",
    "\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_outsample_12.columns:\n",
    "    errors_df_outsample_12[i] = ts_val_actual_flat\n",
    "    \n",
    "errors_df_outsample_copy_12 = errors_df_outsample_12.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:01.570498Z",
     "start_time": "2020-09-07T12:28:54.156319Z"
    }
   },
   "outputs": [],
   "source": [
    "#Out-of-sample fit horizon 36\n",
    "errors_df_outsample_36 = pd.DataFrame(index = preds_df_outsample_36.index, columns = preds_df_outsample_36.columns)\n",
    "\n",
    "#Errors for train\n",
    "ts_val_actual = []\n",
    "for i in index_feats_36:\n",
    "    cur_ts = original_train_T_36['M{}'.format(i)].dropna().tolist()[-24:] + original_test_T_36['M{}'.format(i)].dropna().tolist()[:12]\n",
    "    ts_val_actual.append(cur_ts)\n",
    "    \n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_outsample_36.columns:\n",
    "    errors_df_outsample_36[i] = ts_val_actual_flat\n",
    "    \n",
    "errors_df_outsample_copy_36 = errors_df_outsample_36.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:01.842226Z",
     "start_time": "2020-09-07T12:29:01.572864Z"
    }
   },
   "outputs": [],
   "source": [
    "#Transform into MAPE\n",
    "errors_df_outsample_12 = np.abs(((errors_df_outsample_12 - preds_df_outsample_12)/errors_df_outsample_12)*100)\n",
    "errors_df_outsample_12.index.names = ['unique_id', 'ds']\n",
    "errors_df_outsample_12 = errors_df_outsample_12.groupby('unique_id')[errors_df_outsample_12.columns].mean()\n",
    "\n",
    "errors_df_outsample_36 = np.abs(((errors_df_outsample_36 - preds_df_outsample_36)/errors_df_outsample_36)*100)\n",
    "errors_df_outsample_36.index.names = ['unique_id', 'ds']\n",
    "errors_df_outsample_36 = errors_df_outsample_36.groupby('unique_id')[errors_df_outsample_36.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:01.947740Z",
     "start_time": "2020-09-07T12:29:01.844204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive2</th>\n",
       "      <th>SNaive</th>\n",
       "      <th>RWdrift</th>\n",
       "      <th>ETS</th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.19</td>\n",
       "      <td>12.99</td>\n",
       "      <td>13.92</td>\n",
       "      <td>14.11</td>\n",
       "      <td>12.66</td>\n",
       "      <td>18.69</td>\n",
       "      <td>11.55</td>\n",
       "      <td>16.13</td>\n",
       "      <td>13.21</td>\n",
       "      <td>11.44</td>\n",
       "      <td>12.59</td>\n",
       "      <td>10.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.92</td>\n",
       "      <td>23.39</td>\n",
       "      <td>20.17</td>\n",
       "      <td>26.44</td>\n",
       "      <td>21.76</td>\n",
       "      <td>44.19</td>\n",
       "      <td>20.64</td>\n",
       "      <td>27.46</td>\n",
       "      <td>26.59</td>\n",
       "      <td>20.85</td>\n",
       "      <td>24.45</td>\n",
       "      <td>18.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.92</td>\n",
       "      <td>5.78</td>\n",
       "      <td>7.03</td>\n",
       "      <td>6.86</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.33</td>\n",
       "      <td>7.04</td>\n",
       "      <td>5.56</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>729.99</td>\n",
       "      <td>630.87</td>\n",
       "      <td>368.55</td>\n",
       "      <td>744.80</td>\n",
       "      <td>650.70</td>\n",
       "      <td>2083.55</td>\n",
       "      <td>656.14</td>\n",
       "      <td>419.87</td>\n",
       "      <td>794.15</td>\n",
       "      <td>690.63</td>\n",
       "      <td>794.15</td>\n",
       "      <td>405.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Naive  Naive2  SNaive  RWdrift     ETS  AutoArima   TBATS  DTrendS  \\\n",
       "mean   14.19   12.99   13.92    14.11   12.66      18.69   11.55    16.13   \n",
       "std    25.92   23.39   20.17    26.44   21.76      44.19   20.64    27.46   \n",
       "min     0.00    0.15    0.00     0.15    0.11       0.00    0.00     0.12   \n",
       "50%     6.92    5.78    7.03     6.86    5.89       6.83    5.33     7.04   \n",
       "max   729.99  630.87  368.55   744.80  650.70    2083.55  656.14   419.87   \n",
       "\n",
       "      RWDriftS  LLevelS  LLDTrends  fforma  \n",
       "mean     13.21    11.44      12.59   10.61  \n",
       "std      26.59    20.85      24.45   18.34  \n",
       "min       0.09     0.11       0.09    0.09  \n",
       "50%       5.56     5.36       5.52    4.97  \n",
       "max     794.15   690.63     794.15  405.16  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check FFORMA performance out-of-sample horizon 12 months\n",
    "errors_df_outsample_12.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:02.058206Z",
     "start_time": "2020-09-07T12:29:01.950616Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>Naive2</th>\n",
       "      <th>SNaive</th>\n",
       "      <th>RWdrift</th>\n",
       "      <th>ETS</th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.18</td>\n",
       "      <td>16.37</td>\n",
       "      <td>18.43</td>\n",
       "      <td>18.32</td>\n",
       "      <td>16.87</td>\n",
       "      <td>42.54</td>\n",
       "      <td>21.15</td>\n",
       "      <td>25.11</td>\n",
       "      <td>19.87</td>\n",
       "      <td>15.94</td>\n",
       "      <td>19.49</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.95</td>\n",
       "      <td>23.37</td>\n",
       "      <td>25.77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>23.53</td>\n",
       "      <td>99.59</td>\n",
       "      <td>94.40</td>\n",
       "      <td>50.63</td>\n",
       "      <td>31.69</td>\n",
       "      <td>22.36</td>\n",
       "      <td>31.01</td>\n",
       "      <td>23.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.71</td>\n",
       "      <td>8.90</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.68</td>\n",
       "      <td>9.21</td>\n",
       "      <td>15.72</td>\n",
       "      <td>9.15</td>\n",
       "      <td>10.69</td>\n",
       "      <td>9.53</td>\n",
       "      <td>8.76</td>\n",
       "      <td>9.33</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>547.24</td>\n",
       "      <td>547.24</td>\n",
       "      <td>553.18</td>\n",
       "      <td>530.59</td>\n",
       "      <td>529.25</td>\n",
       "      <td>4763.18</td>\n",
       "      <td>5945.57</td>\n",
       "      <td>1765.89</td>\n",
       "      <td>712.37</td>\n",
       "      <td>509.89</td>\n",
       "      <td>681.55</td>\n",
       "      <td>914.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Naive  Naive2  SNaive  RWdrift     ETS  AutoArima    TBATS  DTrendS  \\\n",
       "mean   17.18   16.37   18.43    18.32   16.87      42.54    21.15    25.11   \n",
       "std    23.95   23.37   25.77    26.55   23.53      99.59    94.40    50.63   \n",
       "min     0.00    0.32    0.26     0.40    0.00       0.18     0.00     0.20   \n",
       "50%     9.71    8.90   10.50     9.68    9.21      15.72     9.15    10.69   \n",
       "max   547.24  547.24  553.18   530.59  529.25    4763.18  5945.57  1765.89   \n",
       "\n",
       "      RWDriftS  LLevelS  LLDTrends  fforma  \n",
       "mean     19.87    15.94      19.49   15.21  \n",
       "std      31.69    22.36      31.01   23.61  \n",
       "min       0.23     0.28       0.23    0.22  \n",
       "50%       9.53     8.76       9.33    8.17  \n",
       "max     712.37   509.89     681.55  914.96  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check FFORMA performance out-of-sample horizon 36 months\n",
    "errors_df_outsample_36.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta-learning models based on MSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:12.504084Z",
     "start_time": "2020-09-07T12:29:11.090692Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create FFORMA predictions out-of-sample for part A and B\n",
    "weights_outsample_y1_12 = scipy.special.softmax(model2_lgb.predict(train_feats_tot1_12), axis = 1)\n",
    "weights_outsample_y2_12 = scipy.special.softmax(model1_lgb.predict(train_feats_tot2_12), axis = 1)\n",
    "\n",
    "preds_df_insample_12 = preds_df_tot_train_12.copy()\n",
    "preds_df_insample_12.index = preds_df_outsample_12.index\n",
    "\n",
    "preds_df_insample1_12 = preds_df_insample_12.loc[preds_df_insample_12.index.get_level_values(0).isin(y_1)]\n",
    "preds_df_insample2_12 = preds_df_insample_12.loc[preds_df_insample_12.index.get_level_values(0).isin(y_2)]\n",
    "\n",
    "preds_df_insample1_12['fforma'] = (np.repeat(weights_outsample_y1_12, 12, axis = 0)*preds_df_insample1_12).sum(axis = 1)\n",
    "preds_df_insample2_12['fforma'] = (np.repeat(weights_outsample_y2_12, 12, axis = 0)*preds_df_insample2_12).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:16.725898Z",
     "start_time": "2020-09-07T12:29:12.507226Z"
    }
   },
   "outputs": [],
   "source": [
    "#Errors\n",
    "errors_df_insample1_12 = pd.DataFrame(index = preds_df_insample1_12.index, columns = preds_df_insample1_12.columns)\n",
    "errors_df_insample2_12 = pd.DataFrame(index = preds_df_insample2_12.index, columns = preds_df_insample2_12.columns)\n",
    "\n",
    "y_1_original = [original_nrs_dict_rev_12[x] for x in y_1]\n",
    "y_2_original = [original_nrs_dict_rev_12[x] for x in y_2]\n",
    "\n",
    "ts_val_actual = []\n",
    "for i in y_1_original:\n",
    "        ts_val_actual.append(original_train_T_12['M{}'.format(i)].dropna().tolist()[-12:])\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_insample1_12.columns:\n",
    "    errors_df_insample1_12[i] = ts_val_actual_flat\n",
    "    \n",
    "ts_val_actual = []\n",
    "for i in y_2_original:\n",
    "        ts_val_actual.append(original_train_T_12['M{}'.format(i)].dropna().tolist()[-12:])\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_insample2_12.columns:\n",
    "    errors_df_insample2_12[i] = ts_val_actual_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:16.829736Z",
     "start_time": "2020-09-07T12:29:16.728120Z"
    }
   },
   "outputs": [],
   "source": [
    "#Duplicate the df\n",
    "errors_df_insample1_copy_12 = errors_df_insample1_12.copy()\n",
    "errors_df_insample2_copy_12 = errors_df_insample2_12.copy()\n",
    "\n",
    "errors_df_insample1_12 = np.abs(((errors_df_insample1_12 - preds_df_insample1_12)/errors_df_insample1_12)*100)\n",
    "errors_df_insample2_12 = np.abs(((errors_df_insample2_12 - preds_df_insample2_12)/errors_df_insample2_12)*100)\n",
    "\n",
    "errors_df_insample1_12 = errors_df_insample1_12.groupby('unique_id')[errors_df_insample1_12.columns].mean()\n",
    "errors_df_insample2_12 = errors_df_insample2_12.groupby('unique_id')[errors_df_insample2_12.columns].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:17.085626Z",
     "start_time": "2020-09-07T12:29:16.832149Z"
    }
   },
   "outputs": [],
   "source": [
    "#Combine the FFORMA prediction dfs\n",
    "preds_df_insample_CI_tot_12 = preds_df_insample1_12.append(preds_df_insample2_12)\n",
    "preds_df_insample_CI_tot_12 = preds_df_insample_CI_tot_12.sort_index()\n",
    "\n",
    "#Create a prediction interval df\n",
    "CI_final_df_12 = pd.DataFrame(index = preds_df_insample_12.index, columns = CI_df_train_12.columns)\n",
    "\n",
    "#put FFORMA predictions in all columns\n",
    "for i in CI_final_df_12.columns:\n",
    "    CI_final_df_12[i] = preds_df_insample_CI_tot_12['fforma'].tolist()\n",
    "\n",
    "#Change index\n",
    "differences_CI_train_vals_12 = list(differences_CI_train_12.index.get_level_values(0))\n",
    "differences_CI_train_vals_12 = [original_nrs_dict_12[x] for x in differences_CI_train_vals_12]\n",
    "differences_CI_train_12.index = pd.MultiIndex.from_tuples(zip(differences_CI_train_vals_12, differences_CI_train_12.index.get_level_values(1)), names = ['unique_id', 'ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:18.344278Z",
     "start_time": "2020-09-07T12:29:17.087523Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Function that determines the prediction interval\"\"\"\n",
    "def get_interval(pd_series):\n",
    "    Name = pd_series.name\n",
    "    difference_series = differences_CI_train_12[Name]\n",
    "    return [[x-y, x+y] for (x,y) in zip(list(pd_series), list(difference_series))]  \n",
    "\n",
    "#Put the intervals in the df\n",
    "for i in CI_final_df_12.columns:\n",
    "    CI_final_df_12[i] = get_interval(CI_final_df_12[i])\n",
    "\n",
    "#Combine the errors dfs\n",
    "errors_df_insample_full_12 = errors_df_insample1_copy_12.append(errors_df_insample2_copy_12)\n",
    "errors_df_insample_full_12 = errors_df_insample_full_12.sort_index()\n",
    "\n",
    "#Drop columns\n",
    "errors_df_insample_full_12 = errors_df_insample_full_12[CI_final_df_12.columns]\n",
    "\n",
    "\"\"\"\n",
    "Function that determines the MSIS value\n",
    "\"\"\"\n",
    "def get_MSIS_value(pd_series):\n",
    "    Name = pd_series.name\n",
    "    CI_series = list(CI_final_df_12[Name])\n",
    "    \n",
    "    #2 times the difference + 2/alpha (lower - actual) if actual<lower + 2/alpha (actual-higher) if actual>higher\n",
    "    return [(y[1]-y[0]) +(2/0.05)*(y[0] - x) if x<y[0] else (y[1]-y[0]) +(2/0.05)*(x - y[1]) if x>y[1] else y[1]-y[0] for (x, y) in zip(list(pd_series), CI_series)]\n",
    "\n",
    "#Calculate the MSIS values\n",
    "for i in errors_df_insample_full_12.columns:\n",
    "    errors_df_insample_full_12[i] = get_MSIS_value(errors_df_insample_full_12[i])\n",
    "\n",
    "errors_df_insample_full_12 = errors_df_insample_full_12.groupby('unique_id').sum()\n",
    "errors_df_insample_full_12 = errors_df_insample_full_12/12\n",
    "\n",
    "#new index\n",
    "index_real_12 = [original_nrs_dict_rev_12[x] for x in errors_df_insample_full_12.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:30.786615Z",
     "start_time": "2020-09-07T12:29:18.346493Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate normalization for the MSIS measure (denominator of the MSIS equation)\n",
    "index_seas_diff_12 = pd.MultiIndex.from_tuples(zip(np.repeat(errors_df_insample_full_12.index, 48), list(range(1, 49))*len(errors_df_insample_full_12.index)), names = ['unique_id', 'ds'])\n",
    "errors_df_insample_full_seas_diff_12 = pd.DataFrame(index = index_seas_diff_12, columns = errors_df_insample_full_12.columns)\n",
    "\n",
    "ts_val_actual = []\n",
    "for i in index_real_12:\n",
    "        ts_val_actual.append(original_train_T_12['M{}'.format(i)].dropna().tolist()[-12-48:-12])\n",
    "ts_val_actual_flat = [item for sublist in ts_val_actual for item in sublist]\n",
    "\n",
    "for i in errors_df_insample_full_seas_diff_12.columns:\n",
    "    errors_df_insample_full_seas_diff_12[i] = ts_val_actual_flat\n",
    "\n",
    "    \n",
    "errors_df_insample_full_seas_diff_12 = errors_df_insample_full_seas_diff_12.groupby(level=0).diff(12).dropna()\n",
    "errors_df_insample_full_seas_diff_12 = np.abs(errors_df_insample_full_seas_diff_12)\n",
    "errors_df_insample_full_seas_diff_12 = errors_df_insample_full_seas_diff_12.groupby('unique_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:30.849051Z",
     "start_time": "2020-09-07T12:29:30.789195Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize the MSIS measure\n",
    "errors_df_insample_full_12 = errors_df_insample_full_12/errors_df_insample_full_seas_diff_12\n",
    "\n",
    "if reload_CI:\n",
    "    optimal_params = {'n_estimators': 157,\n",
    "                      'eta': 0.1,\n",
    "                      'max_depth': 15,\n",
    "                      'subsample': 0.8,\n",
    "                      'colsample_bytree': 0.6}\n",
    "\n",
    "    model_CI = FFORMA(params=optimal_params, early_stopping_rounds = 10, verbose_eval=1, greedy_search = False, CI=True)\n",
    "\n",
    "    model_CI.fit(errors=errors_df_insample_full_12, holdout_feats=train_feats_tot_12, feats=test_feats_tot_12)\n",
    "    \n",
    "#Load the model\n",
    "model_CI_12 = pickle.load(open('./Models/model_CI_12.pickle.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check FFORMA performance of MSIS in-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:31.372518Z",
     "start_time": "2020-09-07T12:29:30.851361Z"
    }
   },
   "outputs": [],
   "source": [
    "#create the predictions\n",
    "preds_insample_CI_12 = preds_df_insample_CI_tot_12[list(CI_df_train_12.columns) + ['fforma']]\n",
    "\n",
    "#Get the ensemble weights for prediction interval\n",
    "CI_pred_weights_insample_12 = scipy.special.softmax(model_CI_12.predict(train_feats_tot_12), axis = 1)\n",
    "\n",
    "\n",
    "differences_CI_train_12['fforma'] = (np.repeat(CI_pred_weights_insample_12, 12, axis = 0)*differences_CI_train_12).sum(axis = 1)\n",
    "\n",
    "\n",
    "#Now we need the actual values\n",
    "actuals_insample_CI_12 = errors_df_insample1_copy_12.append(errors_df_insample2_copy_12)\n",
    "actuals_insample_CI_12 = actuals_insample_CI_12.sort_index()\n",
    "actuals_insample_CI_12 = actuals_insample_CI_12[differences_CI_train_12.columns]\n",
    "actuals_insample_CI_copy_12 = actuals_insample_CI_12.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:31.385964Z",
     "start_time": "2020-09-07T12:29:31.374758Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_MSIS_value_final(pd_series):\n",
    "    Name = pd_series.name\n",
    "    \n",
    "    differences = list(differences_CI_train_12[Name])\n",
    "    actuals = list(pd_series)\n",
    "    predictions = list(preds_insample_CI_12[Name])\n",
    "    \n",
    "    CI_series = list(differences_CI_train_12[Name])\n",
    "    #x = differences, y = actuals, z = predictions    \n",
    "    return [2*x + (2/0.05)*(z-x-y) if y<(z-x) else 2*x + (2/0.05)*(y-(z+x)) if y>(z+x) else 2*x for (x, y, z) in zip(differences, actuals, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:32.038785Z",
     "start_time": "2020-09-07T12:29:31.396851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.02</td>\n",
       "      <td>9.77</td>\n",
       "      <td>10.59</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.48</td>\n",
       "      <td>19.10</td>\n",
       "      <td>20.34</td>\n",
       "      <td>15.22</td>\n",
       "      <td>17.04</td>\n",
       "      <td>16.08</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.96</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.77</td>\n",
       "      <td>5.33</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>440.02</td>\n",
       "      <td>456.43</td>\n",
       "      <td>438.66</td>\n",
       "      <td>429.51</td>\n",
       "      <td>433.25</td>\n",
       "      <td>431.11</td>\n",
       "      <td>433.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AutoArima   TBATS  DTrendS  RWDriftS  LLevelS  LLDTrends  fforma\n",
       "mean      15.02    9.77    10.59      7.70     7.69       7.44    6.23\n",
       "std       24.48   19.10    20.34     15.22    17.04      16.08   14.67\n",
       "min        0.04    0.18     0.15      0.08     0.76       0.08    0.30\n",
       "50%        6.96    4.74     4.77      5.33     4.29       4.57    4.35\n",
       "max      440.02  456.43   438.66    429.51   433.25     431.11  433.63"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate final MSIS values and normalize\n",
    "for i in actuals_insample_CI_12.columns:\n",
    "    actuals_insample_CI_12[i] = get_MSIS_value_final(actuals_insample_CI_12[i])\n",
    "\n",
    "actuals_insample_CI_12 = actuals_insample_CI_12.groupby('unique_id').mean()\n",
    "\n",
    "errors_df_insample_full_seas_diff_12['fforma'] = errors_df_insample_full_seas_diff_12['AutoArima']\n",
    "\n",
    "actuals_insample_CI_12 = actuals_insample_CI_12 / errors_df_insample_full_seas_diff_12\n",
    "\n",
    "actuals_insample_CI_12.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check FFORMA performance of MSIS out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:35.677436Z",
     "start_time": "2020-09-07T12:29:35.163444Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create weights\n",
    "CI_pred_weights_outsample_12 = scipy.special.softmax(model_CI_12.predict(test_feats_tot_12), axis = 1)\n",
    "\n",
    "#Create preds df\n",
    "preds_df_outsample_CI_12 = preds_df_outsample_12[list(preds_df_tot_test_CI_12.columns) + ['fforma']]\n",
    "\n",
    "#Create differences df\n",
    "differences_CI_test_12.index = differences_CI_train_12.index\n",
    "differences_CI_test_12['fforma'] = (np.repeat(CI_pred_weights_outsample_12, 12, axis = 0)*differences_CI_test_12).sum(axis = 1)\n",
    "\n",
    "#Create errors df\n",
    "errors_df_outsample_copy_fin_12 = errors_df_outsample_copy_12[differences_CI_test_12.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:36.583568Z",
     "start_time": "2020-09-07T12:29:36.575745Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_MSIS_value_final(pd_series):\n",
    "    Name = pd_series.name\n",
    "    \n",
    "    differences = list(differences_CI_test_12[Name])\n",
    "    actuals = list(pd_series)\n",
    "    predictions = list(preds_df_outsample_CI_12[Name])\n",
    "    \n",
    "    #x = differences, y = actuals, z = predictions    \n",
    "    return [2*x + (2/0.05)*(z-x-y) if y<(z-x) else 2*x + (2/0.05)*(y-(z+x)) if y>(z+x) else 2*x for (x, y, z) in zip(differences, actuals, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:37.363211Z",
     "start_time": "2020-09-07T12:29:36.850063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.96</td>\n",
       "      <td>10.28</td>\n",
       "      <td>12.37</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.56</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.09</td>\n",
       "      <td>28.93</td>\n",
       "      <td>33.20</td>\n",
       "      <td>30.04</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.43</td>\n",
       "      <td>26.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.34</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1826.66</td>\n",
       "      <td>1654.40</td>\n",
       "      <td>1734.59</td>\n",
       "      <td>1701.58</td>\n",
       "      <td>1732.05</td>\n",
       "      <td>1701.58</td>\n",
       "      <td>1680.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AutoArima    TBATS  DTrendS  RWDriftS  LLevelS  LLDTrends   fforma\n",
       "mean      15.96    10.28    12.37      8.74     8.71       8.56     7.31\n",
       "std       40.09    28.93    33.20     30.04    30.92      30.43    26.98\n",
       "min        0.08     0.13     0.26      0.21     0.34       0.21     0.33\n",
       "50%        7.34     4.99     5.04      5.37     4.34       4.65     4.44\n",
       "max     1826.66  1654.40  1734.59   1701.58  1732.05    1701.58  1680.60"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create MSIS df and normalize\n",
    "for i in errors_df_outsample_copy_fin_12.columns:\n",
    "    errors_df_outsample_copy_fin_12[i] = get_MSIS_value_final(errors_df_outsample_copy_12[i])\n",
    "\n",
    "errors_df_outsample_copy_fin_12 = errors_df_outsample_copy_fin_12.groupby('unique_id').mean()\n",
    "errors_df_outsample_copy_fin_12 = errors_df_outsample_copy_fin_12 / errors_df_insample_full_seas_diff_12\n",
    "errors_df_outsample_copy_fin_12.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check FFORMA performance of MSIS out-of-sample with FFORMA vs individual bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:29:41.252651Z",
     "start_time": "2020-09-07T12:29:40.757649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoArima</th>\n",
       "      <th>TBATS</th>\n",
       "      <th>DTrendS</th>\n",
       "      <th>RWDriftS</th>\n",
       "      <th>LLevelS</th>\n",
       "      <th>LLDTrends</th>\n",
       "      <th>fforma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.13</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.64</td>\n",
       "      <td>7.82</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.66</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.18</td>\n",
       "      <td>27.95</td>\n",
       "      <td>28.76</td>\n",
       "      <td>27.02</td>\n",
       "      <td>27.71</td>\n",
       "      <td>27.45</td>\n",
       "      <td>26.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.09</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.14</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1673.08</td>\n",
       "      <td>1673.20</td>\n",
       "      <td>1674.31</td>\n",
       "      <td>1684.00</td>\n",
       "      <td>1685.12</td>\n",
       "      <td>1684.00</td>\n",
       "      <td>1680.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AutoArima    TBATS  DTrendS  RWDriftS  LLevelS  LLDTrends   fforma\n",
       "mean       9.13     9.11     8.64      7.82     7.53       7.66     7.31\n",
       "std       27.18    27.95    28.76     27.02    27.71      27.45    26.98\n",
       "min        0.11     0.13     0.19      0.21     0.34       0.21     0.33\n",
       "50%        5.09     4.54     4.14      5.14     4.17       4.49     4.44\n",
       "max     1673.08  1673.20  1674.31   1684.00  1685.12    1684.00  1680.60"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create preds df\n",
    "preds_df_outsample_CI_final_12 = preds_df_outsample_CI_12.copy()\n",
    "\n",
    "for i in preds_df_outsample_CI_final_12.columns:\n",
    "    preds_df_outsample_CI_final_12[i] = preds_df_outsample_CI_final_12['fforma']\n",
    "\n",
    "#For this dataframe, use FFORMA point predictions and statistical prediction intervals\n",
    "def get_MSIS_value_final(pd_series):\n",
    "    Name = pd_series.name\n",
    "    \n",
    "    differences = list(differences_CI_test_12[Name])\n",
    "    actuals = list(pd_series)\n",
    "    predictions = list(preds_df_outsample_CI_final_12[Name])\n",
    "    \n",
    "    #x = differences, y = actuals, z = predictions    \n",
    "    return [2*x + (2/0.05)*(z-x-y) if y<(z-x) else 2*x + (2/0.05)*(y-(z+x)) if y>(z+x) else 2*x for (x, y, z) in zip(differences, actuals, predictions)]\n",
    "\n",
    "\n",
    "errors_df_outsample_copy_finfin_12 = errors_df_outsample_copy_12[differences_CI_test_12.columns]\n",
    "\n",
    "#Create MSIS \n",
    "for i in errors_df_outsample_copy_finfin_12.columns:\n",
    "    errors_df_outsample_copy_finfin_12[i] = get_MSIS_value_final(errors_df_outsample_copy_12[i])\n",
    "\n",
    "errors_df_outsample_copy_finfin_12 = errors_df_outsample_copy_finfin_12.groupby('unique_id').mean()\n",
    "errors_df_outsample_copy_finfin_12 = errors_df_outsample_copy_finfin_12 / errors_df_insample_full_seas_diff_12\n",
    "errors_df_outsample_copy_finfin_12.describe().round(2).iloc[[1, 2, 3, 5, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
